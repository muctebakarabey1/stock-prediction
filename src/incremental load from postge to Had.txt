incremental load from postge to Hadoop using scoop

first open dbeaver table name bitcoin_2025
enter a new records 

BEGIN;

INSERT INTO bitcoin_2025 (
    "Timestamp", "Open", "High", "Low", "Close", "Volume", "Datetime", "Price_Range", "MA_Close_10", "MA_Close_30", "Daily_Return", "Close_Increased", "Cumulative_Volume"
) VALUES
    (1711542600, 69930.0, 69950.0, 69910.0, 79940.0, 0.04545678, '2024-03-27 12:30:00.000', 40.0, 69870.0, 69820.0, 0.00143, 1, 37805157),
    (1711542700, 69950.0, 69970.0, 69920.0, 79950.0, 0.04623456, '2024-03-27 12:40:00.000', 50.0, 69880.0, 69830.0, 0.00150, 1, 37805158),
    (1711542800, 69970.0, 69990.0, 69940.0, 79960.0, 0.04698765, '2024-03-27 12:50:00.000', 60.0, 69890.0, 69840.0, 0.00160, 1, 37805159),
    (1711542900, 69980.0, 70000.0, 69950.0, 79970.0, 0.04712345, '2024-03-27 13:00:00.000', 70.0, 69900.0, 69850.0, 0.00170, 1, 37805160),
    (1711543000, 70000.0, 70020.0, 69960.0, 79980.0, 0.04723456, '2024-03-27 13:10:00.000', 80.0, 69910.0, 69860.0, 0.00180, 1, 37805161);

COMMIT;





sqoop import --connect jdbc:postgresql://18.132.73.146:5432/testdb --username consultants --password WelcomeItc@2022 --table bitcoin_2025 --m 1 --target-dir /tmp/bigdata_nov_2024/project2024/incremental -m 1 --incremental append --check-column Cumulative_Volume --last-value 36805900.826118246






